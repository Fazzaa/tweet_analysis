{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from path import *\n",
    "from mysql.connector import Error as MySqlError\n",
    "from bson.json_util import loads\n",
    "from constants import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PW = 'root'\n",
    "\n",
    "def create_db_connection(host_name, user_name, user_password, db_name):\n",
    "\tconnection = mysql.connector.connect(\n",
    "\t\thost=host_name,\n",
    "\t\tuser=user_name,\n",
    "\t\tpasswd=user_password,\n",
    "\t\tdatabase=db_name\n",
    "\t)\n",
    "\treturn connection\n",
    "\n",
    "CONNECTION = create_db_connection(\"localhost\", \"root\", PW, 'maadb_project')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data_from_json(path):\n",
    "\twith open(path, 'r', encoding='utf8') as f:\n",
    "\t\treturn loads(f.read())\n",
    "\n",
    "def get_data_from_db(query):\n",
    "    cursor = CONNECTION.cursor()\n",
    "    cursor.execute(query)\n",
    "    return cursor\n",
    "\n",
    "def exec_query(query):\n",
    "\tcursor = CONNECTION.cursor()\n",
    "\tcursor.execute(query)\n",
    "\tCONNECTION.commit()\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = ['anger', 'anticipation', 'disgust', 'fear', 'hate', 'hope', 'joy', 'like', 'love', 'sadness', 'surprise', 'trust', 'pos', 'neg']\n",
    "\n",
    "resources = {\n",
    "\t'anger': ['EmoSN', 'NRC', 'sentisense'],\n",
    "\t'anticipation': ['NRC', 'sentisense'],\n",
    "\t'disgust': ['NRC', 'sentisense'],\n",
    "\t'hate': ['sentisense'],\n",
    "\t'fear': ['NRC', 'sentisense'],\n",
    "\t'hope': ['sentisense'],\n",
    "\t'joy': ['EmoSN', 'NRC', 'sentisense'],\n",
    "\t'like': ['sentisense'],\n",
    "\t'love': ['sentisense'],\n",
    "\t'neg': ['GI', 'HL', 'ET', 'LIWC'],\n",
    "\t'pos': ['GI', 'HL', 'ET', 'LIWC'],\n",
    "\t'sadness': ['NRC', 'sentisense'],\n",
    "\t'surprise': ['NRC', 'sentisense'],\n",
    "\t'trust': ['NRC']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creazione tabella sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exec_query(\"drop table maadb_project.sentiment\", connection)\n",
    "query = \"\"\"CREATE TABLE `maadb_project`.`sentiment` (\n",
    "\t\t\t`nome` VARCHAR(20) NOT NULL, \n",
    "\t\t\tPRIMARY KEY (`nome`));\"\"\"\n",
    "exec_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserimento dati tabella sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_sentiments():\n",
    "\tquery = \"\"\"INSERT INTO `maadb_project`.`sentiment` (`nome`) VALUES\"\"\"\n",
    "\tinsert = \"\"\"('{}'),\"\"\"\n",
    "\tfor s in sentiments:\n",
    "\t\tquery += insert.format(s)\n",
    "\tquery = query[:-1] + \";\"\n",
    "\texec_query(query)\n",
    "\n",
    "insert_sentiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creazione tabella lexical_resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exec_query(\"drop table maadb_project.lexical_resource\", connection)\n",
    "query = \"\"\"CREATE TABLE `maadb_project`.`lexical_resource` (\n",
    "\t\t\t`id_lex_res` INT NOT NULL AUTO_INCREMENT,\n",
    "\t\t\t`sentiment` VARCHAR(20) NOT NULL,\n",
    "\t\t\t`resource_name` VARCHAR(10) NOT NULL,\n",
    "\t\t\t`number_of_words` INT NOT NULL,\n",
    "\t\t\tPRIMARY KEY (`id_lex_res`),\n",
    "\t\t\tCONSTRAINT `sentiment_lexres`\n",
    "\t\t\tFOREIGN KEY (`sentiment`) REFERENCES `maadb_project`.`sentiment` (`nome`)\n",
    "\t\t\tON DELETE RESTRICT ON UPDATE CASCADE);\n",
    "\t\t\"\"\"\n",
    "exec_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserimento dati tabella lexical_resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical Resources correctly inserted\n"
     ]
    }
   ],
   "source": [
    "def insert_lexical_resources():\n",
    "\tpath = f'{PREP_PATH}/LexResources.json'\n",
    "\tlex_res = retrieve_data_from_json(path)\n",
    "\tquery = \"\"\"INSERT INTO `maadb_project`.`lexical_resource` (`sentiment`, `resource_name`, `number_of_words`) VALUES\"\"\"\n",
    "\tinsert = \"\"\"('{}', '{}', '{}'),\"\"\"\n",
    "\tfor item in lex_res:\n",
    "\t\tquery += insert.format(item[\"sentiment\"], item[\"id\"], item[\"totNumberWords\"])\n",
    "\tquery = query[:-1] + \";\"\n",
    "\texec_query(query)\n",
    "\tprint(\"Lexical Resources correctly inserted\")\n",
    "\n",
    "insert_lexical_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creazione tabella word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exec_query(\"drop table maadb_project.word\")\n",
    "query = \"\"\"CREATE TABLE `maadb_project`.`word` (\n",
    "\t\t\t`id_word` INT NOT NULL AUTO_INCREMENT,\n",
    "\t\t\t`lemma` VARCHAR(200) NOT NULL,\n",
    "\t\t\tPRIMARY KEY (`id_word`));\"\"\"\n",
    "exec_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserimento dati tabella word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserimento parole risorse lessicali completato!\n",
      "Completed anger\n",
      "Completed anticipation\n",
      "Completed disgust\n",
      "Completed fear\n",
      "Completed hate\n",
      "Completed hope\n",
      "Completed joy\n",
      "Completed like\n",
      "Completed love\n",
      "Completed sadness\n",
      "Completed surprise\n",
      "Completed trust\n",
      "Completed pos\n",
      "Completed neg\n",
      "Word correctly inserted\n"
     ]
    }
   ],
   "source": [
    "#circa 1.20 min\n",
    "def insert_word_from_lexical_resource(path):\n",
    "    data = retrieve_data_from_json(path)\n",
    "    query = \"INSERT INTO word (lemma) VALUES\"\n",
    "    insert = '(\"{}\"),'\n",
    "    for res in data:\n",
    "        lemma = res[\"lemma\"]\n",
    "        query += insert.format(lemma)\n",
    "    query = query[:-1] + \";\"\n",
    "    exec_query(query)\n",
    "    print(\"Inserimento parole risorse lessicali completato!\")\n",
    "\n",
    "def insert_word_from_tweet(path):\n",
    "    data = retrieve_data_from_json(path)\n",
    "    query = \"INSERT INTO word (lemma) VALUES\"\n",
    "    insert = '(\"{}\"),'\n",
    "    for tweet in data:\n",
    "        for word in tweet[\"words\"]:\n",
    "            lemma = word[\"lemma\"]\n",
    "            query += insert.format(lemma)\n",
    "    query = query[:-1] + \";\"\n",
    "    exec_query(query)\n",
    "\n",
    "def insert_word_on_db():\n",
    "    path = os.path.join(PREP_PATH, \"LexResourcesWords.json\")\n",
    "    insert_word_from_lexical_resource(path)\n",
    "    for sent in sentiments:\n",
    "        path = os.path.join(PREP_PATH, f\"preprocessed_tweets_{sent}.json\")\n",
    "        if os.path.exists(path):\n",
    "            insert_word_from_tweet(path)\n",
    "        print(f\"Completed {sent}\")\n",
    "    print(\"Word correctly inserted\")\n",
    "\n",
    "insert_word_on_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creazione tabella token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exec_query(\"drop table maadb_project.token\")\n",
    "query = \"\"\"CREATE TABLE `maadb_project`.`token` (\n",
    "\t\t\t`id_token` INT NOT NULL AUTO_INCREMENT,\n",
    "\t\t\t`token` VARCHAR(100) NOT NULL,\n",
    "\t\t\t`type` VARCHAR(20) NOT NULL,\n",
    "\t\t\tPRIMARY KEY (`id_token`));\"\"\"\n",
    "exec_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserimento dati tabella token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Il problema è questa emoticon :\\ per vari motivi:\n",
    "#1. dal sistema può essere letta solo se la scrivi :\\\\ in modo che si indichi che si vuole effettivamente il back slash\n",
    "#2. una volta che riconosco quel tokene provo a passarlo nel formato esso viene rappresentato come la sua effettiva emoticon, ossia :\\\n",
    "#3. questa rappresentazione non va bene nella query e manda in errore\n",
    "\n",
    "def insert_token_of_sent_on_db(path):\n",
    "    data = retrieve_data_from_json(path)\n",
    "    query = \"\"\"INSERT INTO token (token, type) VALUES\"\"\"\n",
    "    insert = '\\n(\"{}\", \"{}\"),'\n",
    "    insert_2 = \"\"\"\\n('{}', '{}'),\"\"\"\n",
    "    i = 0\n",
    "    for tweet in data:\n",
    "        for type in ['emojis', 'emoticons']:\n",
    "            for token in tweet[type]:\n",
    "                if \"'\" in token:\n",
    "                    query += insert.format(token, type)\n",
    "                else:\n",
    "                    query += insert_2.format(token, type)\n",
    "        i += 1\n",
    "    query = query[:-1] + \";\"\n",
    "\n",
    "    exec_query(query)\n",
    "\n",
    "def insert_token_on_db():\n",
    "    for sent in sentiments:\n",
    "        print(sent)\n",
    "        path = os.path.join(PREP_PATH, f\"preprocessed_tweets_{sent}.json\")\n",
    "        if os.path.exists(path):\n",
    "            insert_token_of_sent_on_db(path)\n",
    "    print(\"Non-word tokens correctly inserted\")\n",
    "\n",
    "insert_token_on_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creazione tabella tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exec_query(\"drop table maadb_project.tweet\")\n",
    "query = \"\"\"CREATE TABLE `maadb_project`.`tweet` (\n",
    "\t\t\t`id_tweet` INT NOT NULL AUTO_INCREMENT,\n",
    "\t\t\t`sentiment` VARCHAR(20) NOT NULL,\n",
    "\t\t\t`doc_number` INT NOT NULL,\n",
    "\t\t\tPRIMARY KEY (`id_tweet`),\n",
    "\t\t\tCONSTRAINT `sentiment_tweet`\n",
    "\t\t\tFOREIGN KEY (`sentiment`) REFERENCES `maadb_project`.`sentiment` (`nome`)\n",
    "\t\t\tON DELETE RESTRICT ON UPDATE CASCADE);\"\"\"\n",
    "exec_query(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserimento dati tabella tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed anger\n",
      "Completed anticipation\n",
      "Completed disgust\n",
      "Completed fear\n",
      "Completed hate\n",
      "Completed hope\n",
      "Completed joy\n",
      "Completed like\n",
      "Completed love\n",
      "Completed sadness\n",
      "Completed surprise\n",
      "Completed trust\n",
      "Completed pos\n",
      "Completed neg\n"
     ]
    }
   ],
   "source": [
    "def insert_tweet():\n",
    "\tinsert = \"('{}', '{}'),\"\n",
    "\tfor s in sentiments:\n",
    "\t\tquery = \"\"\"INSERT INTO `maadb_project`.`tweet` (`sentiment`, `doc_number`) VALUES\"\"\"\n",
    "\t\tfor i in range(60000):\n",
    "\t\t\tquery += insert.format(s, i)\n",
    "\t\texec_query(query[:-1] + \";\")\n",
    "\t\tprint(f\"Completed {s}\")\n",
    "insert_tweet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creazione tabella wordsintweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exec_query(\"drop table maadb_project.wordsintweet\")\n",
    "query = \"\"\"CREATE TABLE `maadb_project`.`wordsintweet` (\n",
    "\t\t\t`id_word` INT NOT NULL,\n",
    "\t\t\t`id_tweet` INT NOT NULL,\n",
    "\t\t\t`frequence` INT NOT NULL,\n",
    "\t\t\t`pos_tag` VARCHAR(4) NULL,\n",
    "\t\t\tPRIMARY KEY (`id_word`, `id_tweet`),\n",
    "\t\t\tCONSTRAINT `tweet_id`\n",
    "\t\t\t\tFOREIGN KEY (`id_tweet`) REFERENCES `maadb_project`.`tweet` (`id_tweet`)\n",
    "\t\t\t\tON DELETE CASCADE ON UPDATE CASCADE,\n",
    "\t\t\tCONSTRAINT `word_id`\n",
    "\t\t\t\tFOREIGN KEY (`id_word`) REFERENCES `maadb_project`.`word` (`id_word`)\n",
    "\t\t\t\tON DELETE CASCADE ON UPDATE CASCADE);\"\"\"\n",
    "exec_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserimento dati tabella wordsintweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted tweet of emotion anger\n",
      "Inserted tweet of emotion anticipation\n",
      "Inserted tweet of emotion disgust\n",
      "Inserted tweet of emotion fear\n",
      "Inserted tweet of emotion joy\n",
      "Inserted tweet of emotion sadness\n",
      "Inserted tweet of emotion surprise\n",
      "Inserted tweet of emotion trust\n"
     ]
    }
   ],
   "source": [
    "#45 min\n",
    "def build_words_dict_from_table():\n",
    "    query = f\"SELECT * FROM word\"\n",
    "    data = get_data_from_db(query).fetchall()\n",
    "    lemma_dict = dict((lemma, id) for (id, lemma) in data)\n",
    "    return lemma_dict\n",
    "\n",
    "def build_tweet_dict_from_table():\n",
    "    query = \"SELECT * FROM tweet\"\n",
    "    data = get_data_from_db(query).fetchall()\n",
    "    token_dict = dict(((sentiment, doc_number), id) for (id, sentiment, doc_number) in data)\n",
    "    return token_dict\n",
    "\n",
    "def insert_word_in_tweet_on_db():\n",
    "    word_dict = build_words_dict_from_table()\n",
    "    tweet_dict = build_tweet_dict_from_table()\n",
    "    for s in sentiments:\n",
    "        path = os.path.join(PREP_PATH, f\"preprocessed_tweets_{s}.json\")\n",
    "        if os.path.exists(path):\n",
    "            data = retrieve_data_from_json(path)\n",
    "            query = build_query_string(data, word_dict, tweet_dict, s)\n",
    "            exec_query(query)\n",
    "            print(f\"Inserted tweet of emotion {s}\")\n",
    "\n",
    "def build_query_string(data, word_dict, tweet_dict, sentiment):\n",
    "    query = \"INSERT INTO wordsintweet (id_word, id_tweet, frequence, pos_tag) VALUES\"\n",
    "    insert = '\\n(\"{}\", \"{}\", \"{}\", \"{}\"),'\n",
    "    for tweet in data:\n",
    "        inserted = []\n",
    "        doc_number = tweet['doc_number']\n",
    "        tweet_id = tweet_dict[(sentiment, doc_number)]\n",
    "        for tweet_word in tweet['words']:\n",
    "            lemma = tweet_word['lemma']\n",
    "            if lemma not in inserted:\n",
    "                word_id = word_dict[lemma]\n",
    "                query += insert.format(word_id, tweet_id, tweet_word['freq'], tweet_word['pos_tag'])\n",
    "                inserted.append(lemma)\n",
    "    return query[:-1] + \";\"\n",
    "\n",
    "insert_word_in_tweet_on_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creazione tabella tokensintweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exec_query(\"drop table maadb_project.tokenintweet\")\n",
    "query = \"\"\"CREATE TABLE `maadb_project`.`tokensintweet` (\n",
    "\t\t\t`id_token` INT NOT NULL,\n",
    "\t\t\t`id_tweet` INT NOT NULL,\n",
    "\t\t\t`frequence` INT NOT NULL,\n",
    "\t\t\tPRIMARY KEY (`id_token`, `id_tweet`),\n",
    "\t\t\tCONSTRAINT `tweet_token_id`\n",
    "\t\t\t\tFOREIGN KEY (`id_tweet`) REFERENCES `maadb_project`.`tweet` (`id_tweet`)\n",
    "\t\t\t\tON DELETE CASCADE ON UPDATE CASCADE,\n",
    "\t\t\tCONSTRAINT `token_id`\n",
    "\t\t\t\tFOREIGN KEY (`id_token`) REFERENCES `maadb_project`.`token` (`id_token`)\n",
    "\t\t\t\tON DELETE CASCADE ON UPDATE CASCADE);\"\"\"\n",
    "exec_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserimento dati in tabella tokensintweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creazione tabella wordsinlexres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exec_query(\"drop table maadb_project.wordsinlexres\")\n",
    "query = \"\"\"CREATE TABLE `maadb_project`.`wordsinlexres` (\n",
    "\t\t\t`id_word` INT NOT NULL,\n",
    "\t\t\t`id_lexres` INT NOT NULL,\n",
    "\t\t\tPRIMARY KEY (`id_word`, `id_lexres`),\n",
    "\t\t\tCONSTRAINT `id_word_lexres`\n",
    "\t\t\t\tFOREIGN KEY (`id_word`) REFERENCES `maadb_project`.`word` (`id_word`)\n",
    "\t\t\t\tON DELETE CASCADE ON UPDATE CASCADE,\n",
    "\t\t\tCONSTRAINT `id_lexres`\n",
    "\t\t\t\tFOREIGN KEY (`id_lexres`) REFERENCES `maadb_project`.`lexical_resource` (`id_lex_res`)\n",
    "\t\t\t\tON DELETE CASCADE ON UPDATE CASCADE);\"\"\"\n",
    "exec_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inserimento dati in tabella wordsinlexres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words correctly inserted\n"
     ]
    }
   ],
   "source": [
    "def retrieve_words_from_file(path):\n",
    "    lines = []\n",
    "    with open(path, 'r', encoding='utf8') as f:\n",
    "        lines = [x.rstrip('\\n') for x in f.readlines()]\n",
    "    return [line for line in lines if \"_\" not in line]\n",
    "\n",
    "def build_lex_res_word_dict():\n",
    "    lex_res_word_dict = {}\n",
    "    for sentiment in sentiments:\n",
    "        words_of_res = []\n",
    "        for res in resources[sentiment]:\n",
    "            file_path = os.path.join(PATH, f'{sentiment.capitalize()}/{res}_{sentiment}.txt')\n",
    "            words_of_res = retrieve_words_from_file(file_path)\n",
    "            lex_res_word_dict[(res, sentiment)] = set(words_of_res)\n",
    "    return lex_res_word_dict\n",
    "\n",
    "def build_lex_res_dict_from_table():\n",
    "    query = \"SELECT * FROM lexical_resource\"\n",
    "    data = get_data_from_db(query).fetchall()\n",
    "    token_dict = dict(((resource, sentiment), id) for id, sentiment, resource, _ in data)\n",
    "    return token_dict\n",
    "\n",
    "def insert_words_in_lex_res_in_db():\n",
    "    lex_res_word_dict = build_lex_res_word_dict()\n",
    "    words_dict = build_words_dict_from_table()\n",
    "    lex_res_dict = build_lex_res_dict_from_table()\n",
    "    insert_words_query = \"INSERT INTO wordsinlexres (id_word, id_lexres) VALUES\"\n",
    "    insert = '\\n(\"{}\", \"{}\"),'\n",
    "    for lex_res, words_of_res in lex_res_word_dict.items():\n",
    "        for word in words_of_res:\n",
    "            word_id = words_dict[word]\n",
    "            lex_res_id = lex_res_dict[lex_res]\n",
    "            insert_words_query += insert.format(word_id, lex_res_id)\n",
    "    insert_words_query = insert_words_query[:-1] + \";\"\n",
    "    exec_query(insert_words_query)\n",
    "    print(\"Words correctly inserted\")\n",
    "\n",
    "insert_words_in_lex_res_in_db()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
